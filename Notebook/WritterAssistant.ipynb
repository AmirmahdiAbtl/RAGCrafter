{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c35a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader, UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "llm = ChatGroq(\n",
    "    model_name = \"llama-3.3-70b-versatile\",\n",
    "    temperature = 0.25,\n",
    "    groq_api_key = \"api_key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1499a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://google.github.io/styleguide/docguide/style.html\",\n",
    "    \"https://www.markdownguide.org/basic-syntax/\",\n",
    "    \"https://gist.github.com/rt2zz/e0a1d6ab2682d2c47746950b84c0b6ee\",\n",
    "    \"https://gist.github.com/allysonsilva/85fff14a22bbdf55485be947566cc09e\",\n",
    "    \"https://israelmitolu.hashnode.dev/markdown-for-technical-writers-tips-tricks-and-best-practices\"\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "guideline = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c9a5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "loader = DirectoryLoader('../Cover Letter Generator', glob=\"**/*.py\")  # Load all Python files\n",
    "template_md = DirectoryLoader(\"./\", glob = \"**/*.md\")\n",
    "documents = loader.load()\n",
    "template_md_document = template_md.load()\n",
    "\n",
    "# Combine the text from all loaded documents\n",
    "code_content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "template_content = \"\\n\\n\".join([doc.page_content for doc in template_md_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4ead29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_openapi_spec(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "api = load_openapi_spec(\"openapi.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598f7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548811d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "documents = guideline\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50 \n",
    ")\n",
    "\n",
    "chunked_texts = []\n",
    "for doc in documents:\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    chunked_texts.extend(chunks)\n",
    "\n",
    "vectorstore = FAISS.from_texts(chunked_texts, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560e1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cdb6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", 'code', \"api\"],\n",
    "    template=\"\"\"\n",
    "    You are a Markdown expert who only take a code and description and then write Markdown file in md format not more detail with the context guidelines that were provided.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    Here's the Markdown text you need to review\n",
    "    Question:\n",
    "    {question}\n",
    "    And this is the code of the project :\n",
    "    {code}\n",
    "    And the OpenAPI specs:\n",
    "    {api}\n",
    "    Answer: \n",
    "    Please only write a result in markdown format. Your result should be clear, concise, and actionable.\n",
    "    \"\"\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ea31319",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt_template)  \n",
    "# for longer context map_reduce can be used\n",
    "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "510540dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=combine_docs_chain,  \n",
    "    question_generator=question_generator,  \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b5788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [] \n",
    "question  = \"\"\"\n",
    "This is a project about Language model customization to customize LLama 3.1 for generating cover letter by given job description and then it will convert it into latex file and then give pdf output\n",
    "\n",
    "\"\"\"\n",
    "result = retrieval_qa_chain({\"question\": question, 'code': code_content,\"api\": api, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d7fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Answer:\", result['answer'])\n",
    "# print(\"Source Documents:\", result['source_documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac9974",
   "metadata": {},
   "source": [
    "# Language Model Customization for Cover Letter Generation\n",
    "===========================================================\n",
    "\n",
    "## Overview\n",
    "-----------\n",
    "\n",
    "This project aims to customize the LLaMA 3.1 language model to generate cover letters based on given job descriptions. The model will convert the generated cover letter into a LaTeX file and produce a PDF output.\n",
    "\n",
    "## Requirements\n",
    "------------\n",
    "\n",
    "* Python 3.x\n",
    "* Streamlit\n",
    "* Pylatex\n",
    "* Langchain\n",
    "* Groq API Key\n",
    "\n",
    "## Code\n",
    "-----\n",
    "\n",
    "### Importing Libraries\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "import subprocess\n",
    "from pylatex.utils import NoEscape\n",
    "from pylatex import Document\n",
    "import re\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "```\n",
    "\n",
    "### Initializing the LLM\n",
    "\n",
    "```python\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    groq_api_key=\"api_key\"\n",
    ")\n",
    "```\n",
    "\n",
    "### Defining the Streamlit App\n",
    "\n",
    "```python\n",
    "st.title('Cover Letter Generator')\n",
    "job_description = st.text_area(\"Paste the job description here:\", \"\")\n",
    "```\n",
    "\n",
    "### Generating the Cover Letter\n",
    "\n",
    "```python\n",
    "if st.button('Generate Cover Letter'):\n",
    "    if job_description:\n",
    "        try:\n",
    "            # Create Document and invoke LLM\n",
    "            doc = Document(page_content=job_description)\n",
    "            prompt_extract = PromptTemplate.from_template(\n",
    "                # ... (prompt template)\n",
    "            )\n",
    "            chain = prompt_extract | llm\n",
    "            res = chain.invoke(input={\"doc\": doc.page_content, \"cover_latter\": cover_letter_template})\n",
    "            latex_code = res.content\n",
    "            latex_code = latex_code.replace(\"\\\\\\\\\", '\\\\')\n",
    "            latex_code = latex_code.replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "            # Create LaTeX file and generate PDF\n",
    "            latex_codes = r\"\"\" \\documentclass{letter} ... \"\"\"\n",
    "            create_pdf_from_latex(latex_codes, \"cover_letter\")\n",
    "            st.success('PDF generated successfully! And you can check the main cover_letter.pdf file in the root folder.')\n",
    "        except Exception as e:\n",
    "            st.error(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        st.error('Please paste a job description.')\n",
    "```\n",
    "\n",
    "## Usage\n",
    "-----\n",
    "\n",
    "1. Run the Streamlit app by executing `streamlit run app.py` in your terminal.\n",
    "2. Paste the job description in the text area.\n",
    "3. Click the \"Generate Cover Letter\" button.\n",
    "4. The app will generate a PDF file named \"cover_letter.pdf\" in the root folder.\n",
    "\n",
    "## Notes\n",
    "-----\n",
    "\n",
    "* Make sure to replace the `groq_api_key` with your actual Groq API key.\n",
    "* The `cover_letter_template` is a static template and may need to be modified to fit your specific needs.\n",
    "* The `prompt_extract` template is used to extract the relevant information from the job description and cover letter template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da961a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37d44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa7975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116eb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf6b7b08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Language Model Customization for Cover Letter Generation\n",
      "===========================================================\n",
      "\n",
      "## Overview\n",
      "-----------\n",
      "\n",
      "This project aims to customize the LLaMA 3.1 language model to generate cover letters based on a given job description. The model will convert the generated cover letter into a LaTeX file and produce a PDF output.\n",
      "\n",
      "## Requirements\n",
      "------------\n",
      "\n",
      "* Python 3.x\n",
      "* Streamlit\n",
      "* Pylatex\n",
      "* Langchain\n",
      "* Groq API key\n",
      "\n",
      "## Installation\n",
      "------------\n",
      "\n",
      "```bash\n",
      "pip install streamlit pylatex langchain\n",
      "```\n",
      "\n",
      "## Usage\n",
      "-----\n",
      "\n",
      "1. Clone the repository and navigate to the project directory.\n",
      "2. Install the required dependencies using `pip install -r requirements.txt`.\n",
      "3. Run the Streamlit app using `streamlit run app.py`.\n",
      "4. Paste the job description into the text area.\n",
      "5. Click the \"Generate Cover Letter\" button to generate the cover letter.\n",
      "6. The generated cover letter will be displayed in the text area, and a PDF file will be saved in the root directory.\n",
      "\n",
      "## Code\n",
      "-----\n",
      "\n",
      "### Importing Libraries\n",
      "\n",
      "```python\n",
      "import streamlit as st\n",
      "import subprocess\n",
      "from pylatex.utils import NoEscape\n",
      "from pylatex import Document\n",
      "import re\n",
      "from langchain_groq import ChatGroq\n",
      "from langchain.schema import Document\n",
      "from langchain_core.prompts import PromptTemplate\n",
      "```\n",
      "\n",
      "### Initializing the LLM\n",
      "\n",
      "```python\n",
      "llm = ChatGroq(\n",
      "    model_name=\"llama-3.1-70b-versatile\",\n",
      "    temperature=0,\n",
      "    groq_api_key=\"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\"\n",
      ")\n",
      "```\n",
      "\n",
      "### Defining the Streamlit App\n",
      "\n",
      "```python\n",
      "st.title('Cover Letter Generator')\n",
      "job_description = st.text_area(\"Paste the job description here:\", \"\")\n",
      "```\n",
      "\n",
      "### Generating the Cover Letter\n",
      "\n",
      "```python\n",
      "if st.button('Generate Cover Letter'):\n",
      "    if job_description:\n",
      "        try:\n",
      "            # Create Document and invoke LLM\n",
      "            doc = Document(page_content=job_description)\n",
      "            prompt_extract = PromptTemplate.from_template(\n",
      "                # ... (template code)\n",
      "            )\n",
      "            chain = prompt_extract | llm\n",
      "            res = chain.invoke(input={\"doc\": doc.page_content, \"cover_latter\": cover_letter_template})\n",
      "            latex_code = res.content\n",
      "            latex_code = latex_code.replace(\"\\\\\\\\\", '\\\\')\n",
      "            latex_code = latex_code.replace(\"\\\\n\", \"\\n\")\n",
      "\n",
      "            # Create PDF from LaTeX code\n",
      "            latex_codes = r\"\"\" \\documentclass{letter} \\usepackage{hyperref} \\usepackage[margin=1in, top=1in]{geometry} % Adjust margins here\n",
      "\n",
      "            \\signature{Amirmahdi Aboutalebi} \\address{Genova, Italy \\\\ +393513211513 \\\\ \\href{mailto:amir.abootalebi2001@gmail.com}{amir.abootalebi2001@gmail.com} \\\\ \\href{https://amirmahdiabtl.github.io/}{amirmahdiabtl.github.io}}\n",
      "\n",
      "            \\begin{document}\n",
      "\n",
      "            \\begin{letter}{\"\"\" + \"\" + r\"\"\"} \\opening{Dear Hiring Manager,} \"\"\" + latex_code + r\"\"\"\n",
      "\n",
      "            \\closing{Sincerely,}\n",
      "\n",
      "            \\end{letter}\n",
      "\n",
      "            \\end{document}\n",
      "\n",
      "            \"\"\"\n",
      "            create_pdf_from_latex(latex_codes, \"cover_letter\")\n",
      "            st.success('PDF generated successfully! And you can check the main cover_letter.pdf file in the root folder.')\n",
      "            st.text_area(\"Cover Letter:\", value=latex_code, height=800)\n",
      "        except Exception as e:\n",
      "            st.error(f\"An error occurred: {e}\")\n",
      "    else:\n",
      "        st.error('Please paste a job description.')\n",
      "```\n",
      "\n",
      "## OpenAPI Specs\n",
      "--------------\n",
      "\n",
      "```yml\n",
      "openapi: 3.1.0\n",
      "info:\n",
      "  version: 1.0.0\n",
      "  title: Example API\n",
      "  termsOfService: https://example.com/terms/\n",
      "  contact:\n",
      "    name: Contact our support\n",
      "    email: contact@example.com\n",
      "    url: http://example.com/contact\n",
      "  license:\n",
      "    name: Apache 2.0\n",
      "    url: http://www.apache.org/licenses/LICENSE-2.0.html\n",
      "  x-logo:\n",
      "    url: https://redocly.github.io/openapi-template/logo.png\n",
      "    altText: OpenAPI example logo\n",
      "  description: This is an **example** API to demonstrate features of the OpenAPI specification.\n",
      "tags:\n",
      "  - name: Echo\n",
      "    description: Example echo operations.\n",
      "  - name: User\n",
      "    description: Example actions on user accounts.\n",
      "  - name: Admin\n",
      "    description: Example operations reserved for administrators.\n",
      "  - name: Info\n",
      "    description: Example operations for retrieving information.\n",
      "  - name: Tag\n",
      "    description: This is a tag description.\n",
      "x-tagGroups:\n",
      "  - name: General\n",
      "    tags:\n",
      "      - User\n",
      "      - Info\n",
      "      - Echo\n",
      "  - name: Administration\n",
      "    tags:\n",
      "      - Admin\n",
      "servers:\n",
      "  - url: https://{tenant}/api/v1\n",
      "    variables:\n",
      "      tenant:\n",
      "        default: www\n",
      "        description: Your tenant id\n",
      "  - url: https://example.com/api/v1\n",
      "paths:\n",
      "  /users/{username}:\n",
      "    $ref: paths/users_{username}.yaml\n",
      "  /user:\n",
      "    $ref: paths/user.yaml\n",
      "  /user/list:\n",
      "    $ref: paths/user-status.yaml\n",
      "  /pathItem:\n",
      "    $ref: paths/pathItem.yaml\n",
      "  /pathItemWithExamples:\n",
      "    $ref: paths/pathItemWithExamples.yaml\n",
      "  /echo:\n",
      "    $ref: paths/echo.yaml\n",
      "components:\n",
      "  securitySchemes:\n",
      "    main_auth:\n",
      "      description: Example description text of the OAuth2 scheme.\n",
      "      type: oauth2\n",
      "      flows:\n",
      "        implicit:\n",
      "          authorizationUrl: http://example.com/api/oauth/dialog\n",
      "          scopes:\n",
      "            read:users: read user info\n",
      "            write:users: modify or remove users\n",
      "    api_key:\n",
      "      description: Example description text of the API key scheme.\n",
      "      type: apiKey\n",
      "      in: header\n",
      "      name: api_key\n",
      "    basic_auth:\n",
      "      type: http\n",
      "      scheme: basic\n",
      "webhooks:\n",
      "  userInfo:\n",
      "    post:\n",
      "      summary: New user webhook\n",
      "      description: Information about a new user in the system.\n",
      "      operationId: userInfo\n",
      "      tags:\n",
      "        - Info\n",
      "      requestBody:\n",
      "        content:\n",
      "          application/json:\n",
      "            schema:\n",
      "              $ref: components/schemas/User.yaml\n",
      "      responses:\n",
      "        200:\n",
      "          description: Successfully retrieved information about a new user.\n",
      "      security:\n",
      "        - api_key: []\n",
      "```\n",
      "Markdown generation complete.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"code\", \"api\", \"chunk_instruction\"],\n",
    "    template=\"\"\"\n",
    "    You are a Markdown expert. Use the provided context, project description, code, and API specifications to create a well-structured Markdown file. \n",
    "    Focus on summarizing and explaining each part in a way that’s accessible and useful.\n",
    "\n",
    "    **Guidelines**:\n",
    "    - Use clear headings and subheadings.\n",
    "    - Explain the purpose of each section (e.g., Overview, Setup Instructions, Key Functions, API Usage).\n",
    "    - Only summarize code and API specifications briefly; focus on their purpose and functionality.\n",
    "    - Include examples or sample usage where relevant.\n",
    "    \n",
    "    ## Project Context\n",
    "    {context}\n",
    "\n",
    "    ## Project Description\n",
    "    {question}\n",
    "\n",
    "    ## Code Overview\n",
    "    - Summarize the key parts of the code, providing descriptions for each.\n",
    "    - Example usage or relevant snippets may be included if helpful.\n",
    "\n",
    "    ## API Specifications\n",
    "    {api}\n",
    "    - Summarize the API specifications focusing on key endpoints and parameters.\n",
    "\n",
    "    ## Instructions\n",
    "    {chunk_instruction}\n",
    "\n",
    "    ### Answer (Markdown Chunk):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_markdown_in_chunks(question, code, chunk_size=2000):\n",
    "    chat_history = []\n",
    "\n",
    "    current_markdown = \"\"\n",
    "    chunk_instruction = \"Generate the beginning of the Markdown file (up to ~2000 characters).\"\n",
    "    max_attempts = 2\n",
    "\n",
    "\n",
    "    for attempt in range(max_attempts):\n",
    "        result = retrieval_qa_chain({\n",
    "            \"question\": question,\n",
    "            \"code\": code,\n",
    "            \"api\": api,\n",
    "            \"chat_history\": chat_history,\n",
    "            \"chunk_instruction\": chunk_instruction\n",
    "        })\n",
    "\n",
    "        chunk = result['answer']\n",
    "        current_markdown += chunk\n",
    "\n",
    "        if \"<!-- END_OF_MARKDOWN -->\" in chunk:\n",
    "            break \n",
    "\n",
    "        if attempt == max_attempts - 1:\n",
    "            chunk += \"<!-- END_OF_MARKDOWN -->\" \n",
    "            break\n",
    "\n",
    "        if len(current_markdown) < chunk_size - 500:\n",
    "            chunk_instruction = f\"Continue generating the Markdown from where you left off (aim for around {chunk_size - len(current_markdown)} characters, ending at a logical break if possible).\"\n",
    "        else:\n",
    "            chunk_instruction = \"Conclude the current section of the Markdown and add an end-of-markdown marker if the entire Markdown file is complete. Otherwise, continue to the next section ensuring the chunk ends at a logical breaking point.\"\n",
    "        yield chunk\n",
    "        chat_history.append((question, chunk))\n",
    "\n",
    "\n",
    "\n",
    "question  = \"\"\"\n",
    "This is a project about Language model customization to customize LLama 3.1 for generating cover letter by given job description and then it will convert it into latex file and then give pdf output\n",
    "\n",
    "\"\"\"\n",
    "for markdown_chunk in generate_markdown_in_chunks(question, code_content):\n",
    "    print(markdown_chunk)\n",
    "print(\"Markdown generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db97e22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Language Model Customization for Cover Letter Generation\n",
       "===========================================================\n",
       "\n",
       "## Overview\n",
       "-----------\n",
       "\n",
       "This project aims to customize the LLaMA 3.1 language model to generate cover letters based on a given job description. The model will convert the generated cover letter into a LaTeX file and produce a PDF output.\n",
       "\n",
       "## Requirements\n",
       "------------\n",
       "\n",
       "* Python 3.x\n",
       "* Streamlit\n",
       "* Pylatex\n",
       "* Langchain\n",
       "* Groq API key\n",
       "\n",
       "## Installation\n",
       "------------\n",
       "\n",
       "```bash\n",
       "pip install streamlit pylatex langchain\n",
       "```\n",
       "\n",
       "## Usage\n",
       "-----\n",
       "\n",
       "1. Clone the repository and navigate to the project directory.\n",
       "2. Install the required dependencies using `pip install -r requirements.txt`.\n",
       "3. Run the Streamlit app using `streamlit run app.py`.\n",
       "4. Paste the job description into the text area.\n",
       "5. Click the \"Generate Cover Letter\" button to generate the cover letter.\n",
       "6. The generated cover letter will be displayed in the text area, and a PDF file will be saved in the root directory.\n",
       "\n",
       "## Code\n",
       "-----\n",
       "\n",
       "### Importing Libraries\n",
       "\n",
       "```python\n",
       "import streamlit as st\n",
       "import subprocess\n",
       "from pylatex.utils import NoEscape\n",
       "from pylatex import Document\n",
       "import re\n",
       "from langchain_groq import ChatGroq\n",
       "from langchain.schema import Document\n",
       "from langchain_core.prompts import PromptTemplate\n",
       "```\n",
       "\n",
       "### Initializing the LLM\n",
       "\n",
       "```python\n",
       "llm = ChatGroq(\n",
       "    model_name=\"llama-3.1-70b-versatile\",\n",
       "    temperature=0,\n",
       "    groq_api_key=\"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\"\n",
       ")\n",
       "```\n",
       "\n",
       "### Defining the Streamlit App\n",
       "\n",
       "```python\n",
       "st.title('Cover Letter Generator')\n",
       "job_description = st.text_area(\"Paste the job description here:\", \"\")\n",
       "```\n",
       "\n",
       "### Generating the Cover Letter\n",
       "\n",
       "```python\n",
       "if st.button('Generate Cover Letter'):\n",
       "    if job_description:\n",
       "        try:\n",
       "            # Create Document and invoke LLM\n",
       "            doc = Document(page_content=job_description)\n",
       "            prompt_extract = PromptTemplate.from_template(\n",
       "                # ... (template code)\n",
       "            )\n",
       "            chain = prompt_extract | llm\n",
       "            res = chain.invoke(input={\"doc\": doc.page_content, \"cover_latter\": cover_letter_template})\n",
       "            latex_code = res.content\n",
       "            latex_code = latex_code.replace(\"\\\\\\\\\", '\\\\')\n",
       "            latex_code = latex_code.replace(\"\\\\n\", \"\\n\")\n",
       "\n",
       "            # Create PDF from LaTeX code\n",
       "            latex_codes = r\"\"\" \\documentclass{letter} \\usepackage{hyperref} \\usepackage[margin=1in, top=1in]{geometry} % Adjust margins here\n",
       "\n",
       "            \\signature{Amirmahdi Aboutalebi} \\address{Genova, Italy \\\\ +393513211513 \\\\ \\href{mailto:amir.abootalebi2001@gmail.com}{amir.abootalebi2001@gmail.com} \\\\ \\href{https://amirmahdiabtl.github.io/}{amirmahdiabtl.github.io}}\n",
       "\n",
       "            \\begin{document}\n",
       "\n",
       "            \\begin{letter}{\"\"\" + \"\" + r\"\"\"} \\opening{Dear Hiring Manager,} \"\"\" + latex_code + r\"\"\"\n",
       "\n",
       "            \\closing{Sincerely,}\n",
       "\n",
       "            \\end{letter}\n",
       "\n",
       "            \\end{document}\n",
       "\n",
       "            \"\"\"\n",
       "            create_pdf_from_latex(latex_codes, \"cover_letter\")\n",
       "            st.success('PDF generated successfully! And you can check the main cover_letter.pdf file in the root folder.')\n",
       "            st.text_area(\"Cover Letter:\", value=latex_code, height=800)\n",
       "        except Exception as e:\n",
       "            st.error(f\"An error occurred: {e}\")\n",
       "    else:\n",
       "        st.error('Please paste a job description.')\n",
       "```\n",
       "\n",
       "## OpenAPI Specs\n",
       "--------------\n",
       "\n",
       "```yml\n",
       "openapi: 3.1.0\n",
       "info:\n",
       "  version: 1.0.0\n",
       "  title: Example API\n",
       "  termsOfService: https://example.com/terms/\n",
       "  contact:\n",
       "    name: Contact our support\n",
       "    email: contact@example.com\n",
       "    url: http://example.com/contact\n",
       "  license:\n",
       "    name: Apache 2.0\n",
       "    url: http://www.apache.org/licenses/LICENSE-2.0.html\n",
       "  x-logo:\n",
       "    url: https://redocly.github.io/openapi-template/logo.png\n",
       "    altText: OpenAPI example logo\n",
       "  description: This is an **example** API to demonstrate features of the OpenAPI specification.\n",
       "tags:\n",
       "  - name: Echo\n",
       "    description: Example echo operations.\n",
       "  - name: User\n",
       "    description: Example actions on user accounts.\n",
       "  - name: Admin\n",
       "    description: Example operations reserved for administrators.\n",
       "  - name: Info\n",
       "    description: Example operations for retrieving information.\n",
       "  - name: Tag\n",
       "    description: This is a tag description.\n",
       "x-tagGroups:\n",
       "  - name: General\n",
       "    tags:\n",
       "      - User\n",
       "      - Info\n",
       "      - Echo\n",
       "  - name: Administration\n",
       "    tags:\n",
       "      - Admin\n",
       "servers:\n",
       "  - url: https://{tenant}/api/v1\n",
       "    variables:\n",
       "      tenant:\n",
       "        default: www\n",
       "        description: Your tenant id\n",
       "  - url: https://example.com/api/v1\n",
       "paths:\n",
       "  /users/{username}:\n",
       "    $ref: paths/users_{username}.yaml\n",
       "  /user:\n",
       "    $ref: paths/user.yaml\n",
       "  /user/list:\n",
       "    $ref: paths/user-status.yaml\n",
       "  /pathItem:\n",
       "    $ref: paths/pathItem.yaml\n",
       "  /pathItemWithExamples:\n",
       "    $ref: paths/pathItemWithExamples.yaml\n",
       "  /echo:\n",
       "    $ref: paths/echo.yaml\n",
       "components:\n",
       "  securitySchemes:\n",
       "    main_auth:\n",
       "      description: Example description text of the OAuth2 scheme.\n",
       "      type: oauth2\n",
       "      flows:\n",
       "        implicit:\n",
       "          authorizationUrl: http://example.com/api/oauth/dialog\n",
       "          scopes:\n",
       "            read:users: read user info\n",
       "            write:users: modify or remove users\n",
       "    api_key:\n",
       "      description: Example description text of the API key scheme.\n",
       "      type: apiKey\n",
       "      in: header\n",
       "      name: api_key\n",
       "    basic_auth:\n",
       "      type: http\n",
       "      scheme: basic\n",
       "webhooks:\n",
       "  userInfo:\n",
       "    post:\n",
       "      summary: New user webhook\n",
       "      description: Information about a new user in the system.\n",
       "      operationId: userInfo\n",
       "      tags:\n",
       "        - Info\n",
       "      requestBody:\n",
       "        content:\n",
       "          application/json:\n",
       "            schema:\n",
       "              $ref: components/schemas/User.yaml\n",
       "      responses:\n",
       "        200:\n",
       "          description: Successfully retrieved information about a new user.\n",
       "      security:\n",
       "        - api_key: []\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for markdown_chunk in generate_markdown_in_chunks(question, code_content):\n",
    "    display(Markdown(markdown_chunk))\n",
    "#     display(df.nunique())\n",
    "#     print(markdown_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b9d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
